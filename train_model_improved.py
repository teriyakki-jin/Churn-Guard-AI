import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_auc_score, roc_curve, precision_recall_curve
)
from sklearn.preprocessing import StandardScaler
import joblib
import json
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os

class ImprovedChurnModel:
    """ê°œì„ ëœ ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, model_version="v2.0"):
        self.model_version = model_version
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = None
        self.metrics = {}
        
    def load_and_preprocess_data(self, filepath='backend/data/Customer-Churn.csv'):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ğŸ“Š Loading data...")
        df = pd.read_csv(filepath)
        
        # TotalCharges ì²˜ë¦¬
        df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
        df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)
        
        # customerID ì œê±°
        if 'customerID' in df.columns:
            df.drop('customerID', axis=1, inplace=True)
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ì¸ì½”ë”©
        df['Churn'] = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)
        
        # Feature Engineering
        print("ğŸ”§ Engineering features...")
        
        # 1. ê³ ê° ê°€ì¹˜ ì ìˆ˜
        df['customer_value_score'] = (
            df['tenure'] * 0.3 + 
            (df['MonthlyCharges'] / df['MonthlyCharges'].max()) * 100 * 0.4 +
            (df['TotalCharges'] / df['TotalCharges'].max()) * 100 * 0.3
        )
        
        # 2. ì„œë¹„ìŠ¤ ì‚¬ìš©ëŸ‰
        service_cols = ['PhoneService', 'MultipleLines', 'InternetService', 
                       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
                       'TechSupport', 'StreamingTV', 'StreamingMovies']
        df['total_services'] = df[service_cols].apply(
            lambda x: sum([1 for val in x if val not in ['No', 'No internet service', 'No phone service']]), 
            axis=1
        )
        
        # 3. ì›”ë³„ ì§€ì¶œ ëŒ€ë¹„ ì´ ì§€ì¶œ ë¹„ìœ¨
        df['charge_ratio'] = df['TotalCharges'] / (df['MonthlyCharges'] * df['tenure'] + 1)
        
        # 4. ê³„ì•½ ì•ˆì •ì„± ì ìˆ˜
        contract_scores = {'Month-to-month': 1, 'One year': 2, 'Two year': 3}
        df['contract_stability'] = df['Contract'].map(contract_scores)
        
        # 5. ê²°ì œ ë°©ì‹ ìœ„í—˜ë„
        payment_risk = {
            'Electronic check': 3,
            'Mailed check': 2,
            'Bank transfer (automatic)': 1,
            'Credit card (automatic)': 1
        }
        df['payment_risk'] = df['PaymentMethod'].map(payment_risk)
        
        # One-hot encoding
        categorical_cols = df.select_dtypes(include=['object']).columns
        df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)
        
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        X = df.drop('Churn', axis=1)
        y = df['Churn']
        
        self.feature_names = X.columns.tolist()
        
        return X, y
    
    def train_ensemble_model(self, X_train, y_train):
        """ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ"""
        print("ğŸ¯ Training ensemble model...")
        
        # ê°œë³„ ëª¨ë¸ ì •ì˜
        xgb_model = xgb.XGBClassifier(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='logloss',
            use_label_encoder=False
        )
        
        rf_model = RandomForestClassifier(
            n_estimators=200,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        
        gb_model = GradientBoostingClassifier(
            n_estimators=150,
            learning_rate=0.05,
            max_depth=5,
            random_state=42
        )
        
        # íˆ¬í‘œ ì•™ìƒë¸”
        self.model = VotingClassifier(
            estimators=[
                ('xgb', xgb_model),
                ('rf', rf_model),
                ('gb', gb_model)
            ],
            voting='soft',
            weights=[2, 1, 1]  # XGBoostì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
        )
        
        self.model.fit(X_train, y_train)
        print("âœ… Ensemble model trained successfully!")
        
    def evaluate_model(self, X_test, y_test):
        """ëª¨ë¸ í‰ê°€"""
        print("ğŸ“ˆ Evaluating model...")
        
        y_pred = self.model.predict(X_test)
        y_pred_proba = self.model.predict_proba(X_test)[:, 1]
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        self.metrics = {
            'accuracy': float(accuracy_score(y_test, y_pred)),
            'roc_auc': float(roc_auc_score(y_test, y_pred_proba)),
            'precision': float(classification_report(y_test, y_pred, output_dict=True)['1']['precision']),
            'recall': float(classification_report(y_test, y_pred, output_dict=True)['1']['recall']),
            'f1_score': float(classification_report(y_test, y_pred, output_dict=True)['1']['f1-score'])
        }
        
        print("\nğŸ¯ Model Performance:")
        print(f"Accuracy:  {self.metrics['accuracy']:.4f}")
        print(f"ROC-AUC:   {self.metrics['roc_auc']:.4f}")
        print(f"Precision: {self.metrics['precision']:.4f}")
        print(f"Recall:    {self.metrics['recall']:.4f}")
        print(f"F1-Score:  {self.metrics['f1_score']:.4f}")
        
        print("\nğŸ“Š Classification Report:")
        print(classification_report(y_test, y_pred))
        
        # Confusion Matrix
        cm = confusion_matrix(y_test, y_pred)
        print("\nğŸ”¢ Confusion Matrix:")
        print(cm)
        
        return self.metrics
    
    def get_feature_importance(self):
        """íŠ¹ì„± ì¤‘ìš”ë„ ì¶”ì¶œ"""
        # XGBoost ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„ ì‚¬ìš©
        xgb_model = self.model.named_estimators_['xgb']
        importance = xgb_model.feature_importances_
        
        feature_importance = dict(zip(self.feature_names, importance))
        # ìƒìœ„ 15ê°œë§Œ ì¶”ì¶œ
        sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:15]
        
        return dict(sorted_features)
    
    def save_model(self, output_dir='backend/models'):
        """ëª¨ë¸ ë° ë©”íƒ€ë°ì´í„° ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ëª¨ë¸ ì €ì¥
        model_path = f"{output_dir}/churn_model_{timestamp}.pkl"
        joblib.dump(self.model, model_path)
        print(f"âœ… Model saved: {model_path}")
        
        # Feature names ì €ì¥
        features_path = f"{output_dir}/feature_names_{timestamp}.pkl"
        joblib.dump(self.feature_names, features_path)
        
        # ìµœì‹  ëª¨ë¸ë¡œ ë³µì‚¬
        joblib.dump(self.model, 'backend/churn_model.pkl')
        joblib.dump(self.feature_names, 'backend/feature_names.pkl')
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'model_version': self.model_version,
            'training_date': timestamp,
            'metrics': self.metrics,
            'feature_importance': self.get_feature_importance(),
            'n_features': len(self.feature_names)
        }
        
        metadata_path = f"{output_dir}/model_metadata_{timestamp}.json"
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=4)
        print(f"âœ… Metadata saved: {metadata_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Starting improved model training...\n")
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = ImprovedChurnModel(model_version="v2.0")
    
    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    X, y = model.load_and_preprocess_data()
    
    # ë°ì´í„° ë¶„í•  (stratifyë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"\nğŸ“¦ Train set: {X_train.shape}, Test set: {X_test.shape}")
    print(f"ğŸ“Š Churn rate - Train: {y_train.mean():.2%}, Test: {y_test.mean():.2%}")
    
    # ëª¨ë¸ í•™ìŠµ
    model.train_ensemble_model(X_train, y_train)
    
    # ëª¨ë¸ í‰ê°€
    metrics = model.evaluate_model(X_test, y_test)
    
    # íŠ¹ì„± ì¤‘ìš”ë„
    print("\nğŸ¯ Top Feature Importance:")
    for feature, importance in list(model.get_feature_importance().items())[:10]:
        print(f"  {feature}: {importance:.4f}")
    
    # ëª¨ë¸ ì €ì¥
    model.save_model()
    
    print("\nâœ… Training completed successfully!")

if __name__ == "__main__":
    main()
